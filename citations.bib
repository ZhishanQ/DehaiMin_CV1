
@misc{hu_empirical_2023,
	title = {An {Empirical} {Study} of {Pre}-trained {Language} {Models} in {Simple} {Knowledge} {Graph} {Question} {Answering}},
	url = {http://arxiv.org/abs/2303.10368},
	abstract = {Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find that knowledge distillation techniques and knowledge enhancement methods in PLMs are promising for KGQA. Furthermore, we test ChatGPT, which has drawn a great deal of attention in the NLP community, demonstrating its impressive capabilities and limitations in zero-shot KGQA. We have released the code and benchmarks to promote the use of PLMs on KGQA.},
	urldate = {2023-04-23},
	publisher = {arXiv},
	author = {Hu, Nan and Wu, Yike and Qi, Guilin and Min, Dehai and Chen, Jiaoyan and Pan, Jeff Z. and Ali, Zafar},
	month = mar,
	year = {2023},
	note = {arXiv:2303.10368 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted by World Wide Web Journal},
	file = {arXiv Fulltext PDF:/Users/zhishanqm/Zotero/storage/YSCVUT63/Hu 等 - 2023 - An Empirical Study of Pre-trained Language Models .pdf:application/pdf;arXiv.org Snapshot:/Users/zhishanqm/Zotero/storage/P83YUKYT/2303.html:text/html},
}

@article{hu_empirical_2023-1,
	title = {An empirical study of pre-trained language models in simple knowledge graph question answering},
	issn = {1386-145X, 1573-1413},
	url = {https://link.springer.com/10.1007/s11280-023-01166-y},
	doi = {10.1007/s11280-023-01166-y},
	abstract = {Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efﬁciency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and ﬁnd that knowledge distillation techniques and knowledge enhancement methods in PLMs are promising for KGQA. Furthermore, we test ChatGPT (https://chat.openai.com/), which has drawn a great deal of attention in the NLP community, demonstrating its impressive capabilities and limitations in zero-shot KGQA. We have released the code and benchmarks to promote the use of PLMs on KGQA (https:// github.com/aannonymouuss/PLMs-in-Practical-KBQA).},
	language = {en},
	urldate = {2023-05-28},
	journal = {World Wide Web},
	author = {Hu, Nan and Wu, Yike and Qi, Guilin and Min, Dehai and Chen, Jiaoyan and Pan, Jeff Z and Ali, Zafar},
	month = may,
	year = {2023},
	file = {Hu 等 - 2023 - An empirical study of pre-trained language models .pdf:/Users/zhishanqm/Zotero/storage/KUG2IYST/Hu 等 - 2023 - An empirical study of pre-trained language models .pdf:application/pdf},
}

@misc{min_exploring_2024,
	title = {Exploring the {Impact} of {Table}-to-{Text} {Methods} on {Augmenting} {LLM}-based {Question} {Answering} with {Domain} {Hybrid} {Data}},
	url = {http://arxiv.org/abs/2402.12869},
	doi = {10.48550/arXiv.2402.12869},
	abstract = {Augmenting Large Language Models (LLMs) for Question Answering (QA) with domain specific data has attracted wide attention. However, domain data often exists in a hybrid format, including text and semi-structured tables, posing challenges for the seamless integration of information. Table-to-Text Generation is a promising solution by facilitating the transformation of hybrid data into a uniformly text-formatted corpus. Although this technique has been widely studied by the NLP community, there is currently no comparative analysis on how corpora generated by different table-to-text methods affect the performance of QA systems. In this paper, we address this research gap in two steps. First, we innovatively integrate table-to-text generation into the framework of enhancing LLM-based QA systems with domain hybrid data. Then, we utilize this framework in real-world industrial data to conduct extensive experiments on two types of QA systems (DSFT and RAG frameworks) with four representative methods: Markdown format, Template serialization, TPLM-based method, and LLM-based method. Based on the experimental results, we draw some empirical findings and explore the underlying reasons behind the success of some methods. We hope the findings of this work will provide a valuable reference for the academic and industrial communities in developing robust QA systems.},
	urldate = {2024-03-04},
	publisher = {arXiv},
	author = {Min, Dehai and Hu, Nan and Jin, Rihui and Lin, Nuo and Chen, Jiaoyan and Chen, Yongrui and Li, Yu and Qi, Guilin and Li, Yun and Li, Nijun and Wang, Qianren},
	month = feb,
	year = {2024},
	note = {arXiv:2402.12869 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/zhishanqm/Zotero/storage/4VD2TLT8/Min 等 - 2024 - Exploring the Impact of Table-to-Text Methods on A.pdf:application/pdf;arXiv.org Snapshot:/Users/zhishanqm/Zotero/storage/ISXE3IQP/2402.html:text/html},
}
